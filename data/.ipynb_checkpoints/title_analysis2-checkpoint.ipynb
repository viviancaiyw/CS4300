{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "strong-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thousand-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "TMT_MOVIE_PATH = '/Users/susan/Development/cs4300sp2021-cw887-qh75-rz92-yc687-yl698/data/movie_data/rotten_tomatoes_movies.csv'\n",
    "\n",
    "with open(TMT_MOVIE_PATH, 'r') as f:\n",
    "    movie_df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "statutory-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rotten_tomatoes_link', 'movie_title', 'movie_info',\n",
       "       'critics_consensus', 'content_rating', 'genres', 'directors', 'authors',\n",
       "       'actors', 'original_release_date', 'streaming_release_date', 'runtime',\n",
       "       'production_company', 'tomatometer_status', 'tomatometer_rating',\n",
       "       'tomatometer_count', 'audience_status', 'audience_rating',\n",
       "       'audience_count', 'tomatometer_top_critics_count',\n",
       "       'tomatometer_fresh_critics_count', 'tomatometer_rotten_critics_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "angry-might",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>movie_info</th>\n",
       "      <th>critics_consensus</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>genres</th>\n",
       "      <th>directors</th>\n",
       "      <th>authors</th>\n",
       "      <th>actors</th>\n",
       "      <th>original_release_date</th>\n",
       "      <th>...</th>\n",
       "      <th>production_company</th>\n",
       "      <th>tomatometer_status</th>\n",
       "      <th>tomatometer_rating</th>\n",
       "      <th>tomatometer_count</th>\n",
       "      <th>audience_status</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>audience_count</th>\n",
       "      <th>tomatometer_top_critics_count</th>\n",
       "      <th>tomatometer_fresh_critics_count</th>\n",
       "      <th>tomatometer_rotten_critics_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15365</th>\n",
       "      <td>m/the_lego_movie</td>\n",
       "      <td>The LEGO Movie</td>\n",
       "      <td>Emmet (Chris Pratt), an ordinary LEGO figurine...</td>\n",
       "      <td>Boasting beautiful animation, a charming voice...</td>\n",
       "      <td>PG</td>\n",
       "      <td>Action &amp; Adventure, Animation, Comedy, Kids &amp; ...</td>\n",
       "      <td>Phil Lord, Christopher Miller, Chris McKay</td>\n",
       "      <td>Dan Hageman, Roy Lee, Christopher Miller, Phil...</td>\n",
       "      <td>Chris Pratt, Elizabeth Banks, Will Arnett, Mor...</td>\n",
       "      <td>2014-02-07</td>\n",
       "      <td>...</td>\n",
       "      <td>Warner Bros. Pictures</td>\n",
       "      <td>Certified-Fresh</td>\n",
       "      <td>96.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Upright</td>\n",
       "      <td>87.0</td>\n",
       "      <td>222764.0</td>\n",
       "      <td>51</td>\n",
       "      <td>240</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rotten_tomatoes_link     movie_title  \\\n",
       "15365     m/the_lego_movie  The LEGO Movie   \n",
       "\n",
       "                                              movie_info  \\\n",
       "15365  Emmet (Chris Pratt), an ordinary LEGO figurine...   \n",
       "\n",
       "                                       critics_consensus content_rating  \\\n",
       "15365  Boasting beautiful animation, a charming voice...             PG   \n",
       "\n",
       "                                                  genres  \\\n",
       "15365  Action & Adventure, Animation, Comedy, Kids & ...   \n",
       "\n",
       "                                        directors  \\\n",
       "15365  Phil Lord, Christopher Miller, Chris McKay   \n",
       "\n",
       "                                                 authors  \\\n",
       "15365  Dan Hageman, Roy Lee, Christopher Miller, Phil...   \n",
       "\n",
       "                                                  actors  \\\n",
       "15365  Chris Pratt, Elizabeth Banks, Will Arnett, Mor...   \n",
       "\n",
       "      original_release_date  ...     production_company  tomatometer_status  \\\n",
       "15365            2014-02-07  ...  Warner Bros. Pictures     Certified-Fresh   \n",
       "\n",
       "      tomatometer_rating tomatometer_count  audience_status  audience_rating  \\\n",
       "15365               96.0             250.0          Upright             87.0   \n",
       "\n",
       "      audience_count  tomatometer_top_critics_count  \\\n",
       "15365       222764.0                             51   \n",
       "\n",
       "       tomatometer_fresh_critics_count  tomatometer_rotten_critics_count  \n",
       "15365                              240                                11  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df[movie_df['movie_title'] == 'The LEGO Movie']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-stress",
   "metadata": {},
   "source": [
    "## Get StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "harmful-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = list(set(movie_df['movie_title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "alternate-bronze",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['super hero', 'she is prettier', 'world', 'star war']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stem titles\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def lemmatize_titles(titles_lst):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_res = []\n",
    "#     stemmer = PorterStemmer()\n",
    "#     stem_res = []\n",
    "    for w in titles_lst:\n",
    "        token_lst1 = list(map(lambda x: lemmatizer.lemmatize(x), word_tokenize(w.lower())))\n",
    "#         token_lst2 = list(map(lambda x: stemmer.stem(x), word_tokenize(w.lower())))\n",
    "        lemma_res.append(\" \".join(token_lst1))\n",
    "#         stem_res.append(\" \".join(token_lst2))\n",
    "    return lemma_res\n",
    "    \n",
    "lemmatize_titles(['Super Heros', \"She is prettier\", 'Worlds', 'Star Wars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "stable-april",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'super hero'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_title('Super Heros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "regulation-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lemma_titles = lemmatize_titles(all_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fossil-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    \"\"\"\n",
    "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
    "    \n",
    "    get_top_n_words([\"I love Python\", \"Python is a language programming\", \"Hello world\", \"I love the world\"]) -> \n",
    "    [('python', 2),\n",
    "     ('world', 2),\n",
    "     ('love', 2),\n",
    "     ('hello', 1),\n",
    "     ('is', 1),\n",
    "     ('programming', 1),\n",
    "     ('the', 1),\n",
    "     ('language', 1)]\n",
    "    \"\"\"\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_words = nltk.pos_tag([val[0] for val in words_freq])\n",
    "    \n",
    "    if not n:\n",
    "        return top_words\n",
    "    return top_words[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "similar-phoenix",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('of', 'IN'), ('and', 'CC'), ('in', 'IN'), ('to', 'TO'), ('man', 'NN'), ('love', 'VB'), ('on', 'IN'), ('for', 'IN'), ('my', 'PRP$'), ('life', 'NN'), ('you', 'PRP'), ('day', 'NN'), ('night', 'NN'), ('story', 'NN'), ('girl', 'NN'), ('last', 'JJ'), ('me', 'PRP'), ('with', 'IN'), ('la', 'NN'), ('from', 'IN'), ('is', 'VBZ'), ('it', 'PRP'), ('movie', 'NN'), ('dead', 'JJ'), ('world', 'NN'), ('boy', 'NN'), ('war', 'NN'), ('time', 'NN'), ('de', 'IN'), ('all', 'DT'), ('big', 'JJ'), ('black', 'JJ'), ('one', 'CD'), ('king', 'NN'), ('no', 'DT'), ('ii', 'JJ'), ('american', 'JJ'), ('house', 'NN'), ('le', 'VBD'), ('little', 'JJ'), ('at', 'IN'), ('do', 'VBP'), ('dark', 'JJ'), ('blue', 'VB'), ('white', 'JJ'), ('men', 'NNS'), ('red', 'VBD'), ('an', 'DT'), ('blood', 'NN'), ('woman', 'NN'), ('we', 'PRP'), ('city', 'NN'), ('death', 'NN'), ('up', 'IN'), ('new', 'JJ'), ('good', 'JJ'), ('out', 'RP'), ('who', 'WP'), ('heart', 'NN'), ('lost', 'VBD'), ('go', 'VB'), ('god', 'JJ'), ('dog', 'NN'), ('star', 'VBD'), ('two', 'CD'), ('your', 'PRP$'), ('by', 'IN'), ('what', 'WP'), ('that', 'IN'), ('game', 'NN'), ('mr', 'FW'), ('child', 'NN'), ('road', 'NN'), ('dream', 'NN'), ('home', 'NN'), ('devil', 'NN'), ('return', 'VB'), ('summer', 'NN'), ('kill', 'NNP'), ('christmas', 'VBZ'), ('thing', 'NN'), ('be', 'VB'), ('bad', 'JJ'), ('secret', 'JJ'), ('die', 'NN'), ('year', 'NN'), ('street', 'NN'), ('wild', 'JJ'), ('kid', 'NNS'), ('tale', 'JJ'), ('part', 'NN'), ('high', 'VBZ'), ('this', 'DT'), ('back', 'RB'), ('down', 'RP'), ('first', 'RB'), ('sea', 'NN'), ('monster', 'NN'), ('brother', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "top_words = get_top_n_words(all_lemma_titles)\n",
    "print(top_words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "synthetic-inspection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'and', 'in', 'to', 'man', 'love', 'on', 'for', 'my', 'life', 'you', 'day', 'night', 'story', 'girl', 'last', 'me', 'with', 'la', 'from', 'is', 'it', 'movie', 'dead', 'world', 'boy', 'war', 'time', 'de', 'all', 'no', 'at', 'an', 'we', 'up', 'who', 'your', 'by', 'what', 'that', 'this', 'about', 'like', 'angel', 'after', 'beyond', 'under', 'our', 'before', 'or', 'she', 'into', 'they', 'over', 'bride', 'another', 'her', 'so', 'his', 'without', 'if', 'he', 'mrs', 'than', 'blind', 'through', 'between', 'some', 'upon', 'behind', 'them', 'within', 'but', 'every']\n"
     ]
    }
   ],
   "source": [
    "def get_stop_words(tagged_top_words, add_all_till=0):\n",
    "    stop_types = ['DT', 'IN', 'CC', 'TO', 'PRP$', 'PRP', 'WP']\n",
    "    stop_words = []\n",
    "    idx = 0\n",
    "    while idx < len(tagged_top_words):\n",
    "        word = tagged_top_words[idx][0]\n",
    "        word_type = tagged_top_words[idx][1]\n",
    "        if idx < add_all_till:\n",
    "            stop_words.append(word)\n",
    "        else:\n",
    "            if word_type in stop_types:\n",
    "                stop_words.append(word)      \n",
    "        idx += 1\n",
    "#     stop_words = ['story', 'movie','time', 'ii', 'iii', 'iv', 'v', 'le', 'de', 'days', 'man', 'world', 'girl', 'one', 'two']\n",
    "#     stop_words = [w[0] for w in tagged_top_words if w[1] not in stop_types and w[0] not in stop_words]\n",
    "    return stop_words\n",
    "\n",
    "stop_words = get_stop_words(top_words[:700], 30)\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "statutory-enterprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('of', 'IN')\n",
      "('in', 'IN')\n",
      "('to', 'TO')\n",
      "('on', 'IN')\n",
      "('my', 'PRP$')\n",
      "('me', 'PRP')\n",
      "('la', 'NN')\n",
      "('is', 'VBZ')\n",
      "('it', 'PRP')\n",
      "('de', 'IN')\n",
      "('no', 'DT')\n",
      "('ii', 'JJ')\n",
      "('le', 'VBD')\n",
      "('at', 'IN')\n",
      "('do', 'VBP')\n",
      "('an', 'DT')\n",
      "('we', 'PRP')\n",
      "('up', 'IN')\n",
      "('go', 'VB')\n",
      "('by', 'IN')\n",
      "('mr', 'FW')\n",
      "('be', 'VB')\n",
      "('am', 'VBP')\n",
      "('el', 'VBP')\n",
      "('vs', 'NN')\n",
      "('or', 'CC')\n",
      "('dr', 'JJ')\n",
      "('wa', 'JJ')\n",
      "('re', 'NN')\n",
      "('so', 'IN')\n",
      "('du', 'NN')\n",
      "('di', 'RB')\n",
      "('da', 'NN')\n",
      "('un', 'JJ')\n",
      "('il', 'RB')\n",
      "('if', 'IN')\n",
      "('13', 'CD')\n",
      "('he', 'PRP')\n",
      "('3d', 'CD')\n",
      "('ca', 'MD')\n",
      "('10', 'CD')\n",
      "('ha', 'NN')\n",
      "('st', 'NN')\n",
      "('et', 'VBP')\n",
      "('ll', 'VBP')\n",
      "('11', 'CD')\n",
      "('en', 'FW')\n",
      "('wo', 'MD')\n",
      "('au', 'JJ')\n",
      "('24', 'CD')\n",
      "('si', 'JJ')\n",
      "('20', 'CD')\n",
      "('iv', 'NN')\n",
      "('30', 'CD')\n",
      "('12', 'CD')\n",
      "('ma', 'VBN')\n",
      "('ve', 'NN')\n",
      "('oh', 'JJ')\n",
      "('ho', 'JJ')\n",
      "('mi', 'NN')\n",
      "('ne', 'JJ')\n",
      "('na', 'NNS')\n",
      "('fu', 'NN')\n",
      "('pa', 'NN')\n",
      "('50', 'CD')\n",
      "('17', 'CD')\n",
      "('li', 'NN')\n",
      "('tu', 'NN')\n",
      "('ta', 'NN')\n",
      "('te', 'NN')\n",
      "('ip', 'JJ')\n",
      "('22', 'CD')\n",
      "('ai', 'NN')\n",
      "('21', 'CD')\n",
      "('ex', 'NN')\n",
      "('16', 'CD')\n",
      "('os', 'NN')\n",
      "('oz', 'JJ')\n",
      "('47', 'CD')\n",
      "('al', 'IN')\n",
      "('28', 'CD')\n",
      "('ye', 'NN')\n",
      "('wu', 'NN')\n",
      "('99', 'CD')\n",
      "('ji', 'NN')\n",
      "('14', 'CD')\n",
      "('37', 'CD')\n",
      "('em', 'NN')\n",
      "('dy', 'JJ')\n",
      "('15', 'CD')\n",
      "('45', 'CD')\n",
      "('ni', 'JJ')\n",
      "('je', 'JJ')\n",
      "('lo', 'JJ')\n",
      "('vi', 'NN')\n",
      "('se', 'JJ')\n",
      "('29', 'CD')\n",
      "('18', 'CD')\n",
      "('jr', 'JJ')\n",
      "('40', 'CD')\n",
      "('as', 'IN')\n",
      "('er', 'VBZ')\n",
      "('70', 'CD')\n",
      "('71', 'CD')\n",
      "('vu', 'NN')\n",
      "('nu', 'NN')\n",
      "('ga', 'NN')\n",
      "('51', 'CD')\n",
      "('ed', 'NN')\n",
      "('33', 'CD')\n",
      "('io', 'JJ')\n",
      "('23', 'CD')\n",
      "('ou', 'NN')\n",
      "('60', 'CD')\n",
      "('27', 'CD')\n",
      "('44', 'CD')\n",
      "('19', 'CD')\n",
      "('jo', 'NN')\n",
      "('54', 'CD')\n",
      "('ke', 'NN')\n",
      "('39', 'CD')\n",
      "('ju', 'NN')\n",
      "('yo', 'NN')\n",
      "('ya', 'NN')\n",
      "('36', 'CD')\n",
      "('mo', 'NN')\n",
      "('ol', 'IN')\n",
      "('yu', 'NN')\n",
      "('gi', 'NN')\n",
      "('xi', 'NNP')\n",
      "('42', 'CD')\n",
      "('55', 'CD')\n",
      "('om', 'NN')\n",
      "('31', 'CD')\n",
      "('bi', 'JJ')\n",
      "('ri', 'NN')\n",
      "('pi', 'NN')\n",
      "('vj', 'NN')\n",
      "('xx', 'NNP')\n",
      "('ny', 'NN')\n",
      "('fe', 'JJ')\n",
      "('ka', 'NN')\n",
      "('76', 'CD')\n",
      "('gu', 'NN')\n",
      "('80', 'CD')\n",
      "('48', 'CD')\n",
      "('hr', 'NN')\n",
      "('ra', 'NN')\n",
      "('yi', 'CC')\n",
      "('81', 'CD')\n",
      "('52', 'CD')\n",
      "('ja', 'NN')\n",
      "('fi', 'NN')\n",
      "('tv', 'NN')\n",
      "('po', 'NN')\n",
      "('ax', 'RP')\n",
      "('6e', 'CD')\n",
      "('im', 'NN')\n",
      "('04', 'CD')\n",
      "('96', 'CD')\n",
      "('qi', 'NN')\n",
      "('68', 'CD')\n",
      "('hd', 'NN')\n",
      "('56', 'CD')\n",
      "('ot', 'NN')\n",
      "('ox', 'NN')\n",
      "('62', 'CD')\n",
      "('us', 'PRP')\n",
      "('t2', 'NN')\n",
      "('lu', 'JJ')\n",
      "('rû', 'NN')\n",
      "('på', 'NN')\n",
      "('rv', 'NN')\n",
      "('57', 'CD')\n",
      "('49', 'CD')\n",
      "('où', 'NN')\n",
      "('cô', 'NN')\n",
      "('xv', 'NNP')\n",
      "('5b', 'CD')\n",
      "('xy', 'NNP')\n",
      "('fm', 'NN')\n",
      "('ko', 'NN')\n",
      "('fp', 'JJ')\n",
      "('ki', 'NN')\n",
      "('ut', 'JJ')\n",
      "('og', 'NN')\n",
      "('hi', 'NN')\n",
      "('x2', 'JJ')\n",
      "('a2', 'NN')\n",
      "('ak', 'NN')\n",
      "('ah', 'NN')\n",
      "('zi', 'NN')\n",
      "('h2', 'NN')\n",
      "('86', 'CD')\n",
      "('ab', 'NN')\n",
      "('90', 'CD')\n",
      "('jk', 'NN')\n",
      "('u2', 'JJ')\n",
      "('bb', 'NN')\n",
      "('43', 'CD')\n",
      "('bo', 'NN')\n",
      "('p2', 'NN')\n",
      "('61', 'CD')\n",
      "('ae', 'NN')\n",
      "('sa', 'NN')\n",
      "('73', 'CD')\n",
      "('08', 'CD')\n",
      "('ur', 'JJ')\n",
      "('za', 'NN')\n",
      "('ao', 'JJ')\n",
      "('ad', 'NN')\n",
      "('kk', 'VBD')\n",
      "('d2', 'JJ')\n",
      "('cq', 'NN')\n",
      "('va', 'NN')\n",
      "('jt', 'NN')\n",
      "('ce', 'NN')\n",
      "('és', 'NNP')\n",
      "('ro', 'NN')\n",
      "('84', 'CD')\n",
      "('78', 'CD')\n",
      "('46', 'CD')\n",
      "('af', 'NN')\n",
      "('2u', 'CD')\n",
      "('gw', 'NN')\n",
      "('um', 'JJ')\n",
      "('pt', 'NN')\n",
      "('95', 'CD')\n",
      "('4d', 'CD')\n",
      "('hu', 'NN')\n",
      "('d3', 'NN')\n",
      "('k2', 'VBD')\n",
      "('77', 'CD')\n",
      "('83', 'CD')\n",
      "('só', 'NN')\n",
      "('há', 'NN')\n",
      "('ee', 'JJ')\n",
      "('jû', 'JJ')\n",
      "('4x', 'CD')\n",
      "('pu', 'NN')\n",
      "('ms', 'NN')\n",
      "('id', 'NN')\n",
      "('66', 'CD')\n",
      "('ci', 'NN')\n",
      "('mu', 'NN')\n",
      "('qu', 'NN')\n",
      "('ek', 'NN')\n",
      "('93', 'CD')\n",
      "('eg', 'NN')\n",
      "('88', 'CD')\n"
     ]
    }
   ],
   "source": [
    "for w in top_words:\n",
    "    if len(w[0]) == 2:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "laughing-recruitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'and', 'in', 'to', 'man', 'love', 'on', 'for', 'my', 'life', 'you', 'day', 'night', 'story', 'girl', 'last', 'me', 'with', 'la', 'from', 'is', 'it', 'movie', 'dead', 'world', 'boy', 'war', 'time', 'de', 'all', 'no', 'at', 'an', 'we', 'up', 'who', 'your', 'by', 'what', 'that', 'this', 'about', 'like', 'after', 'beyond', 'under', 'our', 'before', 'or', 'she', 'into', 'they', 'over', 'another', 'her', 'so', 'his', 'without', 'if', 'he', 'mrs', 'than', 'through', 'between', 'some', 'upon', 'behind', 'them', 'within', 'but', 'every', 's', 'll']\n"
     ]
    }
   ],
   "source": [
    "stop_words =  list(filter(lambda x: x not in ['blind', 'angel', 'bride'], stop_words))\n",
    "stop_words.append(\"s\")\n",
    "stop_words.append(\"ll\")\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-marine",
   "metadata": {},
   "source": [
    "# Filter Games and Movies with Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "brave-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_title(title, stop_words=stop_words):\n",
    "    filtered_title = re.sub('\\W+',' ', title.lower()).strip().split(\" \")\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = list(filter(lambda x: x not in stop_words, filtered_title))\n",
    "    token_lst1 = list(map(lambda x: lemmatizer.lemmatize(x), tokens))\n",
    "    print(f'filtered_title = {filtered_title}')\n",
    "    print(f'tokens = {tokens}')\n",
    "    print(f'lemmatizer.lemmatize(x) = {token_lst1}')\n",
    "    return \" \".join(token_lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "alleged-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer = PorterStemmer()\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# stemmer.stem('flowers'), lemmatizer.lemmatize('flowers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "subjective-praise",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered_title_dict = dict() # <rotten_path, filtered_name>  \n",
    "inv_filtered_title_dict = dict() # <filtered_name, rotten_path>\n",
    "\n",
    "count = 0\n",
    "for idx, row in movie_df.iterrows():\n",
    "    if type(row['rotten_tomatoes_link']) is str:\n",
    "        rotten_tmt = row['rotten_tomatoes_link'].split('/')[1]\n",
    "        filtered_title = filter_title(row['movie_title'], stop_words)\n",
    "        filtered_title_dict[rotten_tmt] = filtered_title\n",
    "        if filtered_title not in inv_filtered_title_dict:\n",
    "            inv_filtered_title_dict[filtered_title] = []\n",
    "        inv_filtered_title_dict[filtered_title].append(rotten_tmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "gross-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "inv_filtered_title = os.path.join('movie_data', 'inv_filtered_title_lyt.json')\n",
    "filtered_title = os.path.join('movie_data', 'filtered_title_lyt.json')\n",
    "json.dump(filtered_title_dict, open(filtered_title, 'w+'), indent=4)\n",
    "json.dump(inv_filtered_title_dict, open(inv_filtered_title, 'w+'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "divided-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_games = os.path.join('steamData', 'available_games', 'available_game_filtered_title.csv')\n",
    "with open(available_games, 'r') as f:\n",
    "    games_df = pd.read_csv(available_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "banned-latin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>app_id</th>\n",
       "      <th>filtered_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Among Us</td>\n",
       "      <td>945360</td>\n",
       "      <td>among</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "      <td>730</td>\n",
       "      <td>counter strike global offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              name  app_id  \\\n",
       "0           0                          Among Us  945360   \n",
       "1           1  Counter-Strike: Global Offensive     730   \n",
       "\n",
       "                     filtered_name  \n",
       "0                            among  \n",
       "1  counter strike global offensive  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "valuable-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = games_df[{'name', 'app_id'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "psychological-delivery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_title = ['assassin', 's', 'creed', 'odyssey']\n",
      "tokens = ['assassin', 'creed', 'odyssey']\n"
     ]
    }
   ],
   "source": [
    "# movie_data_df['filtered_name'] = movie_data_df.apply(lambda x: get_filtered_mov_name(x), axis=1)\n",
    "\n",
    "games_df['filtered_name'] = games_df.apply(lambda x: filter_title(x['name'], stop_words), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "mobile-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, row in games_df.iterrows():\n",
    "#     row['filtered_name'] = filter_title(row['name'], stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "differential-medicare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>name</th>\n",
       "      <th>filtered_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>812140</td>\n",
       "      <td>Assassin's Creed® Odyssey</td>\n",
       "      <td>assassin creed odyssey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     app_id                       name           filtered_name\n",
       "192  812140  Assassin's Creed® Odyssey  assassin creed odyssey"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df[games_df['app_id'] == 812140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "owned-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df.to_csv(available_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "plain-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_filtered_title_dict = dict() # <app_id, filtered_name>  \n",
    "game_inv_filtered_title_dict = dict() # <filtered_name, app_id>\n",
    "\n",
    "count = 0\n",
    "for idx, row in games_df.iterrows():\n",
    "    app_id = str(row['app_id'])\n",
    "    filtered_title = row['filtered_name']\n",
    "    game_filtered_title_dict[app_id] = filtered_title\n",
    "    if filtered_title not in game_inv_filtered_title_dict:\n",
    "        game_inv_filtered_title_dict[filtered_title] = dict()\n",
    "    game_inv_filtered_title_dict[filtered_title] = app_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "regulated-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_filtered_title = os.path.join('steamData', 'available_games', 'inv_filtered_title_lyt.json')\n",
    "game_inv_filtered_title = os.path.join('steamData', 'available_games', 'filtered_title_lyt.json')\n",
    "json.dump(game_filtered_title, open(game_filtered_title, 'w+'), indent=4)\n",
    "json.dump(game_inv_filtered_title, open(game_inv_filtered_title, 'w+'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "final-plaintiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/susan/Development/cs4300sp2021-cw887-qh75-rz92-yc687-yl698/data/steamData/available_games/inv_filtered_title_lyt.json\n"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath(game_filtered_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-waterproof",
   "metadata": {},
   "source": [
    "## Get Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "passive-green",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_similarity_score(val1, val2):\n",
    "    val_lst1 = val1.strip().split(' ')\n",
    "    val_lst2 = val2.strip().split(' ')\n",
    "    \n",
    "    val_count1 = dict(Counter(val_lst1))\n",
    "    val_count2 = dict(Counter(val_lst2))\n",
    "    \n",
    "    common_keys = set(val_count1.keys()).intersection(set(val_count2.keys()))\n",
    "    denom = 0\n",
    "    for k in common_keys:\n",
    "        denom += min(val_count1[k], val_count2[k]) \n",
    "    return denom / len(val_lst2)\n",
    "\n",
    "\n",
    "print(get_similarity_score('lego', 'lego world   '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "israeli-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_name_list = list(sorted(list(set(games_df['filtered_name']))))\n",
    "movies_name_list = list(sorted(list(set(inv_filtered_title_dict.keys()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "considered-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_k(names, scores, k=10):\n",
    "    top_k_scores = np.argsort(scores)[::-1][:k]\n",
    "    for idx in top_k_scores:\n",
    "        print(names[idx], scores[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "accessible-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_name_sim_score_list = []\n",
    "for name in games_name_list:\n",
    "    games_name_sim_score_list.append(get_similarity_score('assassin creed odyssey', name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "hawaiian-inquiry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assassin creed odyssey 1.0\n",
      "assassin creed origin 0.6666666666666666\n",
      "assassin creed brotherhood 0.6666666666666666\n",
      "assassin creed revelation 0.6666666666666666\n",
      "assassin creed rogue 0.6666666666666666\n",
      "assassin creed syndicate 0.6666666666666666\n",
      "assassin creed unity 0.6666666666666666\n",
      "assassin creed odyssey fate atlantis 0.6\n",
      "assassin creed iii remastered 0.5\n",
      "abyss odyssey 0.5\n"
     ]
    }
   ],
   "source": [
    "print_top_k(games_name_list, games_name_sim_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "agricultural-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_movie_info(score_lst, games_name_list, k=100, filtered_zeros=True):\n",
    "    res = []\n",
    "    sorted_idx = np.argsort(score_lst)[::-1]\n",
    "    if not k:\n",
    "        k = len(sorted_idx)\n",
    "    for i in range(k):\n",
    "        idx = sorted_idx[i]\n",
    "        if score_lst[idx] > 0:\n",
    "            res.append([games_name_list[idx], score_lst[idx]])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "billion-indonesia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['assassin creed odyssey', 1.0],\n",
       " ['assassin creed origin', 0.6666666666666666],\n",
       " ['assassin creed brotherhood', 0.6666666666666666],\n",
       " ['assassin creed revelation', 0.6666666666666666],\n",
       " ['assassin creed rogue', 0.6666666666666666],\n",
       " ['assassin creed syndicate', 0.6666666666666666],\n",
       " ['assassin creed unity', 0.6666666666666666],\n",
       " ['assassin creed odyssey fate atlantis', 0.6],\n",
       " ['assassin creed iii remastered', 0.5],\n",
       " ['abyss odyssey', 0.5],\n",
       " ['assassin creed director cut edition', 0.4],\n",
       " ['assassin creed iv black flag', 0.4],\n",
       " ['assassin creed origin curse pharaoh', 0.4],\n",
       " ['assassin creed 2 deluxe edition', 0.4],\n",
       " ['assassin creed origin hidden one', 0.4],\n",
       " ['enslaved odyssey west premium edition', 0.2],\n",
       " ['witcher 2 assassin king enhanced edition', 0.16666666666666666],\n",
       " ['3030 deathwar redux a space odyssey', 0.16666666666666666]]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_movie_info(games_name_sim_score_list, games_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "whole-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_sim_scores(games_name_list=games_name_list, movies_name_list=movies_name_list):\n",
    "    sim_json = dict()\n",
    "\n",
    "    count = 0\n",
    "    start = time.time()\n",
    "    for mov_name in movies_name_list:\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print(f'{count}: {time.time() - start}')\n",
    "        score_lst = []\n",
    "        for game_name in games_name_list:\n",
    "            score_lst.append(get_similarity_score(mov_name, game_name))\n",
    "        sim_json[mov_name] = get_top_movie_info(score_lst, games_name_list)\n",
    "    return sim_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "inner-purchase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000: 17.889000177383423\n",
      "2000: 35.41371417045593\n",
      "3000: 53.06220602989197\n",
      "4000: 70.48846507072449\n",
      "5000: 87.98923301696777\n",
      "6000: 105.4511981010437\n",
      "7000: 123.35684299468994\n",
      "8000: 140.9596860408783\n",
      "9000: 158.57317399978638\n",
      "10000: 176.10992288589478\n",
      "11000: 195.1186079978943\n",
      "12000: 217.07870197296143\n",
      "13000: 235.6496319770813\n",
      "14000: 254.09561586380005\n",
      "15000: 271.8267590999603\n",
      "16000: 291.6538951396942\n"
     ]
    }
   ],
   "source": [
    "name_sim_dict = get_sim_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "offshore-vietnam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['assassin creed origin', 0.6666666666666666],\n",
       " ['assassin creed brotherhood', 0.6666666666666666],\n",
       " ['assassin creed odyssey', 0.6666666666666666],\n",
       " ['assassin creed revelation', 0.6666666666666666],\n",
       " ['assassin creed rogue', 0.6666666666666666],\n",
       " ['assassin creed syndicate', 0.6666666666666666],\n",
       " ['assassin creed unity', 0.6666666666666666],\n",
       " ['assassin creed iii remastered', 0.5],\n",
       " ['assassin creed iv black flag', 0.4],\n",
       " ['assassin creed odyssey fate atlantis', 0.4],\n",
       " ['assassin creed 2 deluxe edition', 0.4],\n",
       " ['assassin creed origin curse pharaoh', 0.4],\n",
       " ['assassin creed origin hidden one', 0.4],\n",
       " ['assassin creed director cut edition', 0.4],\n",
       " ['witcher 2 assassin king enhanced edition', 0.16666666666666666]]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_sim_dict['assassin creed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "chinese-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(name_sim_dict, open(os.path.join('steamData', '80k_data', 'movie_game_title_similarity_5.json'),'w+'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_filtered_title = os.path.join('movie_data', 'inv_filtered_title_lyt.json')\n",
    "filtered_title = os.path.join('movie_data', 'filtered_title_lyt.json')\n",
    "movie_filtered_title = json.load(filtered_title_dict, open(filtered_title, 'r'), indent=4)\n",
    "movie_inv_filtered_title = json.load(inv_filtered_title_dict, open(inv_filtered_title, 'r'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_names_to_id(cur_json, movie_inv_filtered_title_dict=inv_filtered_title_dict):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial_venv",
   "language": "python",
   "name": "tutorial_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
